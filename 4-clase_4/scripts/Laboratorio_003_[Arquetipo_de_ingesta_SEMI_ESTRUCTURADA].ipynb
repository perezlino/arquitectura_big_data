{"cells":[{"cell_type":"markdown","metadata":{},"source":["### 1. Instalación e inicialización de Spark"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Actualización de los repositorios de UBUNTU\n","!sudo apt-get update"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Instalación de JAVA\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Descarga de SPARK\n","!wget -q https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Des-zipeado del instalador\n","!tar xf spark-2.4.8-bin-hadoop2.7.tgz"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Instalación de Spark en Python\n","!pip install -q findspark"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Configuración de variables de entorno\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Inicialización de Spark\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Verificación de la sesión de Spark\n","spark"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Creación de estructura de directorios para las capas LANDING_TMP y LANDING"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Librería para manipulación del sistema de archivos\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Supongamos que vamos a ingestar del servidor \"VISA\" un archivo semi estructurado\n","#\n","# - ENTIDAD TRANSACCIONES_BANCARIAS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos el directorio asociado al servidor desde donde vamos a ingestar los datos para la capa \"LANDING_TMP\"\n","os.mkdir('/content/drive/MyDrive/DATALAKE/LANDING_TMP/VISA')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos el directorio para \"TRANSACCIONES_BANCARIAS\" en \"LANDING_TMP\"\n","os.mkdir('/content/drive/MyDrive/DATALAKE/LANDING_TMP/VISA/TRANSACCIONES_BANCARIAS')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos el directorio asociado al servidor desde donde vamos a ingestar los datos para la capa \"LANDING\"\n","os.mkdir('/content/drive/MyDrive/DATALAKE/LANDING/VISA')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creamos el directorio para \"TRANSACCIONES_BANCARIAS\" en \"LANDING\"\n","os.mkdir('/content/drive/MyDrive/DATALAKE/LANDING/VISA/TRANSACCIONES_BANCARIAS')"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Subir archivos a la capa LANDING_TMP"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Subimos los datos de TRANSACCIONES_BANCARIAS (el archivo 'transacciones_bancarias.txt') a \"LANDING_TMP/VISA/TRANSACCIONES_BANCARIAS\""]},{"cell_type":"markdown","metadata":{},"source":["### 4. Utilizamos Spark para leer datos de la capa LANDING_TMP como dataframe  "]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a339813d-616c-4b86-b614-6a2aea314190","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------+--------------------------+--------------------+\n","|EMPRESA       |PERSONA                   |TRANSACCION         |\n","+--------------+--------------------------+--------------------+\n","|{6, Google}   |{24, 24, Amaya, 1801.0}   |{2018-12-05, 1745.0}|\n","|{10, Sony}    |{32, 1, Carl, 20095.0}    |{2018-04-19, 238.0} |\n","|{2, Microsoft}|{34, 65, Nehru, 12423.0}  |{2018-04-19, 4097.0}|\n","|{5, Amazon}   |{23, 71, Doris, 11538.0}  |{2018-12-05, 1548.0}|\n","|{5, Amazon}   |{45, 83, Giselle, 2503.0} |{2018-04-19, 2233.0}|\n","|{4, Toyota}   |{42, 96, Amos, 15855.0}   |{2018-04-19, 2887.0}|\n","|{9, IBM}      |{70, 19, Laura, 17403.0}  |{2018-04-19, 286.0} |\n","|{4, Toyota}   |{67, 40, Ross, 14285.0}   |{2018-04-19, 974.0} |\n","|{8, HP}       |{57, 100, Cynthia, 8682.0}|{2018-04-19, 2698.0}|\n","|{2, Microsoft}|{22, 22, Kibo, 7449.0}    |{2018-12-05, 1398.0}|\n","+--------------+--------------------------+--------------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Leemos los datos como dataframe\n","dfTransaccionesBancarias = spark.read.format(\"json\").load(\"/content/drive/MyDrive/DATALAKE/LANDING_TMP/VISA/TRANSACCIONES_BANCARIAS\")\n","\n","# Mostramos los datos\n","dfTransaccionesBancarias.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"5d35ab65-3b15-497c-8b0c-8d0c3f19d38e","showTitle":false,"title":""}},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- EMPRESA: struct (nullable = true)\n"," |    |-- ID_EMPRESA: string (nullable = true)\n"," |    |-- NOMBRE_EMPRESA: string (nullable = true)\n"," |-- PERSONA: struct (nullable = true)\n"," |    |-- EDAD: long (nullable = true)\n"," |    |-- ID_PERSONA: string (nullable = true)\n"," |    |-- NOMBRE_PERSONA: string (nullable = true)\n"," |    |-- SALARIO: double (nullable = true)\n"," |-- TRANSACCION: struct (nullable = true)\n"," |    |-- FECHA: string (nullable = true)\n"," |    |-- MONTO: double (nullable = true)\n","\n"]}],"source":["# Tendremos una estructura de tipos semi estructurada\n","dfTransaccionesBancarias.printSchema()"]},{"cell_type":"markdown","metadata":{},"source":["### 5. Utilizamos Spark para escribir datos de la capa LANDING_TMP en la capa LANDING"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Escribimos los datos binarizándolos en la partición de la fecha correspondiente en \"LANDING\" para \"TRANSACCIONES_BANCARIAS\"\n","dfTransaccionesBancarias.write.format(\"parquet\").mode(\"overwrite\").save(\"/content/drive/MyDrive/DATALAKE/LANDING/VISA/TRANSACCIONES_BANCARIAS/2018-04-19\")"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"dashboards":[],"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"ejemplo_2","notebookOrigID":1710252427357398,"widgets":{}},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
